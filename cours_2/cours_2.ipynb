{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/cours_2_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/CF_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_11.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/CF_12.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/HR_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/AI_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.coef_: [-0.01841002  0.66643157 -0.00954378  0.09255818  0.09841242  0.03537588\n",
      "  0.05306677 -0.03699934 -0.03070391]\n",
      "\n",
      "lr.intercept_: 2.738351254480287\n",
      "\n",
      "\n",
      "Training mse:  1.1467944606927987\n",
      "\n",
      "Training r2:  0.3036194681962495\n",
      "\n",
      "\n",
      "Test mse:  1.2990942585698801\n",
      "\n",
      "Test r2:  0.16689421958822104\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\n\\nTraining mse: \", mse_train)\n",
    "print(\"\\nTraining r2: \", r2_train)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nTest mse: \", mse_test)\n",
    "print(\"\\nTest r2: \", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.coef_: [ 0.          0.53731972  0.01206909  0.          0.04733905  0.01432853\n",
      "  0.         -0.         -0.        ]\n",
      "\n",
      "lr.intercept_: 2.686977299874552\n",
      "\n",
      "Training mse:  1.1006509971686493\n",
      "\n",
      "Training r2:  0.27688106434608284\n",
      "\n",
      "Test mse:  1.5002477010472157\n",
      "\n",
      "Test r2:  0.22707546660129452\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=40)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "#model = LinearRegression()\n",
    "#model = Ridge(alpha = 10)\n",
    "model = Lasso(alpha = .1)\n",
    "#model = ElasticNet(alpha=.01, l1_ratio = .05)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nTraining r2: \", r2_train)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "print(\"\\nTest r2: \", r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Training mse:  1.1630841733813415\n",
      "\n",
      "Training r2:  0.2884153779557871\n",
      "\n",
      "Test mse:  1.283353999826951\n",
      "\n",
      "Test r2:  0.17599644573815298\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.001\n",
      "\n",
      "Training mse:  1.1630841733876482\n",
      "\n",
      "Training r2:  0.2884153779519286\n",
      "\n",
      "Test mse:  1.28335311331578\n",
      "\n",
      "Test r2:  0.17599701494069242\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Training mse:  1.1630841740119362\n",
      "\n",
      "Training r2:  0.2884153775699839\n",
      "\n",
      "Test mse:  1.283345135792988\n",
      "\n",
      "Test r2:  0.17600213707155865\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Training mse:  1.163084236381323\n",
      "\n",
      "Training r2:  0.2884153394118717\n",
      "\n",
      "Test mse:  1.2832654671681114\n",
      "\n",
      "Test r2:  0.17605328993356728\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1.0\n",
      "\n",
      "Training mse:  1.1630904144198373\n",
      "\n",
      "Training r2:  0.28841155963625287\n",
      "\n",
      "Test mse:  1.2824793484092842\n",
      "\n",
      "Test r2:  0.17655803348167098\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  10.0\n",
      "\n",
      "Training mse:  1.1636541329623664\n",
      "\n",
      "Training r2:  0.28806667191857493\n",
      "\n",
      "Test mse:  1.275589278570987\n",
      "\n",
      "Test r2:  0.18098194304725834\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  100.0\n",
      "\n",
      "Training mse:  1.1917339727037002\n",
      "\n",
      "Training r2:  0.27088719118390947\n",
      "\n",
      "Test mse:  1.2573619506692244\n",
      "\n",
      "Test r2:  0.1926851698870653\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nTraining r2: \", r2_train)\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "mse_test_min = mse_test\n",
    "\n",
    "for i in range(7):\n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTraining r2: \", r2_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "        print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "for i in range(7):\n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTraining r2: \", r2_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "        print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        by_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "        \n",
    "        if mse_test < mse_test_min:\n",
    "            mse_test_min = mse_test\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nTraining r2: \", r2_train)\n",
    "            print(\"\\nTest mse: \", mse_test)\n",
    "            print(\"\\nTest r2: \", r2_test)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Training mse:  1.1175284511510861\n",
      "\n",
      "Validation mse:  1.336501087193961\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "        \n",
    "        if mse_valid < mse_valid_min:\n",
    "            mse_valid_min = mse_valid\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training mse:  1.140982939946361\n",
      "\n",
      "Training r2:  0.29749336618889777\n",
      "\n",
      "Test mse:  1.531917471677924\n",
      "\n",
      "Test r2:  -0.42952797181145086\n",
      "\n",
      "model.coef_: [-0.01917877  0.64293176  0.07429414  0.04972269  0.08556524  0.04095564\n",
      "  0.05801186 -0.02191542 -0.03891519]\n",
      "\n",
      "model.intercept_: 2.8771043771111113\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train_full = mean_squared_error(y_train_full, y_train_full_pred)\n",
    "r2_train_full = r2_score(y_train_full, y_train_full_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train_full)\n",
    "print(\"\\nTraining r2: \", r2_train_full)\n",
    "\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Training mse:  1.1650665053318559\n",
      "\n",
      "Validation mse:  1.1983958143628217\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = SGDRegressor(alpha = 0.0001*(10**i), max_iter=100000, learning_rate='constant', eta0=.100)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.878149378149117e-17\n",
      "-6.878149378149117e-17\n",
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Moyenne r2:  0.2568900458282938\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.001\n",
      "\n",
      "Moyenne r2:  0.2568901755047025\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Moyenne r2:  0.2568913419443709\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Moyenne r2:  0.2569029422703751\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1.0\n",
      "\n",
      "Moyenne r2:  0.2570126198480135\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  10.0\n",
      "\n",
      "Moyenne r2:  0.2575499123039169\n",
      "\n",
      "\n",
      "Algorithme: Lasso\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Moyenne r2:  0.26116564900440914\n",
      "\n",
      "\n",
      "Algorithme: Lasso\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Moyenne r2:  0.26532740344768324\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print(np.mean(X_train[:,0]))\n",
    "print(np.mean(X_train[:,0]))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "r2_max = np.mean(r2_scores)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    if np.mean(r2_scores) > r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "    if np.mean(r2_scores) > r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nAlgorithme: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "        r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "        if np.mean(r2_scores) > r2_max:\n",
    "            r2_max = np.mean(r2_scores)\n",
    "            print(\"\\n\\nAlgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nMoyenne r2: \", r2_max)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training r2:  0.2738562589584391\n",
      "\n",
      "Test r2:  0.16058111528906427\n",
      "\n",
      "model.coef_: [ 0.         0.5705757  0.         0.         0.0269514  0.\n",
      "  0.        -0.        -0.       ]\n",
      "\n",
      "model.intercept_: 2.7542087542053872\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTraining r2: \", r2_train)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vanilla\n",
      "\n",
      "Score r2 =  0.22533068684915597\n",
      "\n",
      "\n",
      "Ridge\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 10}\n",
      "\n",
      "Score r2 =  0.2267699909925829\n",
      "\n",
      "Lasso\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 0.1}\n",
      "\n",
      "Score r2 =  0.2425834037291083\n",
      "\n",
      "ElasticNet\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 0.0001, 'model__l1_ratio': 1000}\n",
      "\n",
      "Score r2 =  0.2483676562070778\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "k_folds = 10\n",
    "\n",
    "# vanilla\n",
    "\n",
    "lr = Pipeline(steps = [('scaler', StandardScaler()), ('model', LinearRegression())])\n",
    "lr_score = cross_val_score(lr, X_train, y_train, cv=k_folds)\n",
    "print('\\n\\nVanilla')\n",
    "print('\\nScore r2 = ', np.mean(lr_score))\n",
    "\n",
    "# Ridge\n",
    "\n",
    "model = Ridge(max_iter = 100000)\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nRidge')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "\n",
    "# Lasso\n",
    "\n",
    "model = Lasso()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nLasso')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "# ElasticNet\n",
    "\n",
    "model = ElasticNet(max_iter=100000)\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\\\n",
    "         'model__l1_ratio':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nElasticNet')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training r2:  0.2738562589584391\n",
      "\n",
      "Test r2:  -26.791044602653088\n",
      "\n",
      "model.coef_: [ 0.         0.5705757  0.         0.         0.0269514  0.\n",
      "  0.        -0.        -0.       ]\n",
      "\n",
      "model.intercept_: 2.7542087542053872\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train_full = r2_score(y_train_full, y_train_full_pred)\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTraining r2: \", r2_train_full)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " <img src=\"./img/V_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ridge\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 100}\n",
      "\n",
      "Score r2 =  0.11714939013664122\n",
      "\n",
      "Test r2 =  0.09502921599882315\n",
      "\n",
      "\n",
      "Lasso\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 0.1}\n",
      "\n",
      "Score r2 =  0.26586655375768675\n",
      "\n",
      "Test r2 =  0.12546046134417047\n",
      "\n",
      "\n",
      "ElasticNet\n",
      "\n",
      "Meilleur paramètre:  {'model__alpha': 0.0001, 'model__l1_ratio': 1000}\n",
      "\n",
      "Score r2 =  0.2734796835644329\n",
      "\n",
      "Test r2 =  0.1302080201240685\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "k_folds = 5\n",
    "\n",
    "# Ridge\n",
    "\n",
    "model = Ridge(max_iter = 100000)\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X, y)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nRidge')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n",
    "# Lasso\n",
    "\n",
    "model = Lasso()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nLasso')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n",
    "# ElasticNet\n",
    "\n",
    "model = ElasticNet()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\\\n",
    "         'model__l1_ratio':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nElasticNet')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "PHASE ENTRAÏNEMENT\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[ 97  45]\n",
      " [ 49 106]] \n",
      "\n",
      "\n",
      "Justesse: \n",
      "\n",
      " 0.6835016835016835 \n",
      "\n",
      "\n",
      "Précision: \n",
      "\n",
      " 0.7019867549668874 \n",
      "\n",
      "\n",
      "Rappel: \n",
      "\n",
      " 0.6838709677419355 \n",
      "\n",
      "\n",
      "Score F1: \n",
      "\n",
      " 0.6928104575163399 \n",
      "\n",
      "\n",
      "AUC: \n",
      "\n",
      " 0.6834847796456156 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PHASE TEST\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      " [[23 18]\n",
      " [12 22]] \n",
      "\n",
      "\n",
      "Justesse: \n",
      "\n",
      " 0.6 \n",
      "\n",
      "\n",
      "Précision: \n",
      "\n",
      " 0.55 \n",
      "\n",
      "\n",
      "Rappel: \n",
      "\n",
      " 0.6470588235294118 \n",
      "\n",
      "\n",
      "Score F1: \n",
      "\n",
      " 0.5945945945945946 \n",
      "\n",
      "\n",
      "AUC: \n",
      "\n",
      " 0.6040172166427547 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les fonctions de prétraitement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n\\n\\n\\nPHASE ENTRAÎNEMENT\\n\\n')\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "cfm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "accuracy  = accuracy_score(y_train, y_train_pred)\n",
    "precision = precision_score(y_train, y_train_pred)\n",
    "recall    = recall_score(y_train, y_train_pred)\n",
    "f1        = f1_score(y_train, y_train_pred)\n",
    "auc       = roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "\n",
    "print('Justesse: \\n\\n', accuracy, '\\n\\n')\n",
    "print('Précision: \\n\\n', precision, '\\n\\n')\n",
    "print('Rappel: \\n\\n', recall, '\\n\\n')\n",
    "print('Score F1: \\n\\n', f1, '\\n\\n')\n",
    "print('AUC: \\n\\n', auc, '\\n\\n')\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print('\\n\\n\\n\\nPHASE TEST\\n\\n')\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "cfm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "accuracy  = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall    = recall_score(y_test, y_test_pred)\n",
    "f1        = f1_score(y_test, y_test_pred)\n",
    "auc       = roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "\n",
    "print('Justesse: \\n\\n', accuracy, '\\n\\n')\n",
    "print('Précision: \\n\\n', precision, '\\n\\n')\n",
    "print('Rappel: \\n\\n', recall, '\\n\\n')\n",
    "print('Score F1: \\n\\n', f1, '\\n\\n')\n",
    "print('AUC: \\n\\n', auc, '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
