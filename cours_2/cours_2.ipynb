{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plan du cours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_1_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/cours_2_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/R_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/R_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_11.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_12.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_13.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_14.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_15.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_16.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_17.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_18.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_19.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_20.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_21.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_22.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_23.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_24.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_25.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_26.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_27.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_28.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_29.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_30.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_31.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.coef_: [ 0.06601087  0.47814892  0.00581202  0.04016063  0.06416465  0.0008025\n",
      "  0.06438654 -0.00985774 -0.09950176]\n",
      "\n",
      "lr.intercept_: 2.8599907963151747e-17\n",
      "\n",
      "Training mse:  0.717813919220143\n",
      "\n",
      "Test mse:  0.7466952460961271\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# instantiate model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Affichons les tailles d'effet R-deux\n",
    "print(\"\\nTest mse: \", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# instantiate model\n",
    "#model = LinearRegression()\n",
    "#model = Ridge(alpha = 10)\n",
    "model = Lasso(alpha = .1)\n",
    "#model = ElasticNet(alpha=.01, l1_ratio = .05)\n",
    "\n",
    "# fit \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Affichons les tailles d'effet R-deux\n",
    "print(\"\\nTest mse: \", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "#X = boston_df.drop('PRICE', axis = 1)\n",
    "#y = boston_df['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "mse_test_min = mse_test\n",
    "\n",
    "for i in range(7):\n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "for i in range(7):\n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        by_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        \n",
    "        if mse_test < mse_test_min:\n",
    "            mse_test_min = mse_test\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nTest mse: \", mse_test)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_32.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_33.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Training mse:  1.1650665053318559\n",
      "\n",
      "Validation mse:  1.1960963427420421\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.001\n",
      "\n",
      "Training mse:  1.1650665053319484\n",
      "\n",
      "Validation mse:  1.1960961683840703\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Training mse:  1.1650665053411344\n",
      "\n",
      "Validation mse:  1.19609459923875\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Training mse:  1.1650665062580918\n",
      "\n",
      "Validation mse:  1.196078915341236\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1.0\n",
      "\n",
      "Training mse:  1.1650665963879294\n",
      "\n",
      "Validation mse:  1.1959228217228586\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  10.0\n",
      "\n",
      "Training mse:  1.1650743880731438\n",
      "\n",
      "Validation mse:  1.1944280413418857\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  100.0\n",
      "\n",
      "Training mse:  1.1654870590540032\n",
      "\n",
      "Validation mse:  1.1831539139685852\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1000.0\n",
      "\n",
      "Training mse:  1.1754182445794727\n",
      "\n",
      "Validation mse:  1.149989378619858\n",
      "\n",
      "\n",
      "algorithm: Lasso\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Training mse:  1.171974207654126\n",
      "\n",
      "Validation mse:  1.141771143102145\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "X_train_full = preprocessing.scale(X_train_full)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_valid = preprocessing.scale(X_valid)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "y_train_full = preprocessing.scale(y_train_full)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_valid = preprocessing.scale(y_valid)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train_full.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "        \n",
    "        if mse_valid < mse_valid_min:\n",
    "            mse_valid_min = mse_valid\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model_best = 'Lasso'\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final, max_iter=100000)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train_full = mean_squared_error(y_train_full, y_train_full_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nAlgorithm: \", model_best)\n",
    "print(\"\\nAlpha: \", alpha_final)\n",
    "print(\"\\nTraining mse: \", mse_train_full)\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 9)\n",
      "(237, 9)\n",
      "(60, 9)\n",
      "(75, 9)\n",
      "(297,)\n",
      "(237,)\n",
      "(60,)\n",
      "(75,)\n",
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Training mse:  0.708019826691409\n",
      "\n",
      "Validation mse:  0.7510563300944657\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.001\n",
      "\n",
      "Training mse:  0.7085691522215699\n",
      "\n",
      "Validation mse:  0.7459153030839047\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Training mse:  0.7085940707917096\n",
      "\n",
      "Validation mse:  0.7422496086271841\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Training mse:  0.7088063123807066\n",
      "\n",
      "Validation mse:  0.7411053639900144\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1.0\n",
      "\n",
      "Training mse:  0.7114801846541249\n",
      "\n",
      "Validation mse:  0.737752512302324\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "X_train_full = preprocessing.scale(X_train_full)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_valid = preprocessing.scale(X_valid)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "y_train_full = preprocessing.scale(y_train_full)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_valid = preprocessing.scale(y_valid)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "print(X_train_full.shape)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train_full.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = SGDRegressor(alpha = 0.0001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_34.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_35.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_36.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_37.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_38.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_39.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des scores r2:  0.2568900458282937\n",
      "Écart type des scores r2:  0.2568900458282937\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "X_train_full = preprocessing.scale(X_train_full)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_valid = preprocessing.scale(X_valid)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "y_train_full = preprocessing.scale(y_train_full)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_valid = preprocessing.scale(y_valid)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "print('Moyenne des scores r2: ', np.mean(r2_scores))\n",
    "print('Écart type des scores r2: ', np.mean(r2_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "algorithm: vanilla\n",
      "\n",
      "Moyenne r2:  0.2568900458282937\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  100.0\n",
      "\n",
      "Moyenne r2:  0.24059908143172484\n",
      "\n",
      "\n",
      "algorithm: Ridge\n",
      "\n",
      "alpha:  1000.0\n",
      "\n",
      "Moyenne r2:  0.1063301456070747\n",
      "\n",
      "\n",
      "algorithm: Lasso\n",
      "\n",
      "alpha:  0.001\n",
      "\n",
      "Moyenne r2:  0.25748797958050806\n",
      "\n",
      "\n",
      "algorithm: Lasso\n",
      "\n",
      "alpha:  0.01\n",
      "\n",
      "Moyenne r2:  0.26217912520305575\n",
      "\n",
      "\n",
      "algorithm: Lasso\n",
      "\n",
      "alpha:  0.1\n",
      "\n",
      "Moyenne r2:  0.2624335093580231\n",
      "\n",
      "\n",
      " Algorithm finished\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "X_train_full = preprocessing.scale(X_train_full)\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_valid = preprocessing.scale(X_valid)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "y_train_full = preprocessing.scale(y_train_full)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_valid = preprocessing.scale(y_valid)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "r2_max = np.mean(r2_scores)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    if np.mean(r2_scores) < r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "    if np.mean(r2_scores) > r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "        r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "        if np.mean(r2_scores) > r2_max:\n",
    "            r2_max = np.mean(r2_scores)\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nMoyenne r2: \", r2_max)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_40.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 2. Méthodes de validation\n",
    "\n",
    "Si nous avions accès à (presque) toute la population pour réaliser nos analyses, les méthodes de validation seraient inutiles. Notre échantillon d'entraînement serait très bien généralisable à n'importe quel autre échantillon tiré au hasard d'une même population.\n",
    "\n",
    "Cependant, on n'a jamais en pratique une telle taille d'échantillon.\n",
    "\n",
    "Les méthode de validation sont donc extrêmement importantes afin d'évaluer la capacité des modèles estimés à prédire les futures données qui leur seront soumises!\n",
    "\n",
    "Concrètement, on souhaite minimiser le biais (associé au sous-apprentissage), tout en minimisant la variance (associé au surapprentissagge).\n",
    "* Minimiser le biais ET la variance est ce qui permet de minimiser l'erreur de prédiction sur de nouvelles données!\n",
    "\n",
    "## 2.1. Trois ensembles de données distincts\n",
    "\n",
    "La méthode la plus simple pour s'assurer d'optimiser la capacité de généralisation de notre modèle est de travailler avec trois ensembles de données:\n",
    "1. Un ensemble d'entraînement.\n",
    "2. Un ensemble de validation.\n",
    "3. Un ensemble de test.\n",
    "\n",
    "Les ensembles d'entrainement et de validation travaillent main dans la main pour trouver le meilleur compromis biais-variance.\n",
    "- Pour obtenir un modèle qui apprenne suffisamment (qui évite le sous-apprentissage) tout en n'apprenant pas trop (qui évite le surapprentissage).\n",
    "\n",
    "1. L'ensemble d'entraînement est utilisé pour estimer les paramètres du modèle.\n",
    "2. L'ensemble de validation va évaluer la capacité de généralisation du modèle.\n",
    "  - Aucune estimation des paramètres n'est alors réalisée.\n",
    "\n",
    "On va généralement itérer entre les étapes 1 et 2, en faisant varier différents **hyperparamètres**.\n",
    "- Un hyperparamètre est un paramètre dont la valeur est fixée avant le début de l'apprentissage.\n",
    "- Un hyperparamètre est généralement associé à la forme du modèle ou à la procédure d'apprentissage.\n",
    "\n",
    "Exemple : \n",
    "- On pourrait faire une régression linéaire multiple en utilisant trois modèles différents:\n",
    "  - un modèle d'ordre 1 (linéaire);\n",
    "  - un modèle d'ordre 2 (quadratique);\n",
    "  - un modèle d'ordre 3 (cuubique).\n",
    "- On estime les paramètres de chacun des trois modèles à l'aide du même ensemble d'entraînement.\n",
    "- On vérifie ensuite quel modèle fait les meilleures prédictions à l'aide de l'ensemble de validation.\n",
    "  - Le meilleur modèle sur l'ensemble de validation est notre modèle final.\n",
    "  \n",
    "Problème: l'évaluation de la capacité de généralisation de notre modèle est réalisée à l'aide d'un ensemble de données (l'ensemble de validation) qui a servi à la sélection du modèle... \n",
    "- L'ensemble de validation est en conflit d'intérêt!\n",
    "\n",
    "Solution: l'évaluation finale de la capacité de généralisation de notre modèle est réalisée à l'aide d'un troisième ensemble de données, soit l'ensemble de test!\n",
    "\n",
    "Note: il est très important que l'ordre des participants dans l'échantillon global soit rendu aléatoire avant de procéder à la division en trois sous-ensembles!\n",
    "- Sinon, la variance d'un échantillon à l'autre sera plus grande et la capacité de généralisation en sera réduite.\n",
    "\n",
    "Une difficulté est qu'on ne souhaite généralement pas diminuer la représentativité de notre ensemble d'entraînement en diminuant sa taille... or, ici, on doit diviser notre échantillon en trois sous-ensembles (entraînement, validation, test)!\n",
    "\n",
    "Une manière de conserver ces trois étapes cruciales (entraînement, validation, test), tout en utilisant une portion plus importante de données pour l'estimation des paramètres est une méthode qu'on appelle **validation croisée**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 4. Apprentissage supervisé: classification\n",
    "\n",
    "- Un type d'analyse souvent réalisé en statistiques inférentielles classiques cherche à rejeter l'hypothèse nulle selon laquelle deux groupes d'individus proviennent de la même population en ce qui a trait à une ou plusieurs variables.\n",
    "  - Le chercheur tente alors de supporter une hypotèse alternative selon laquelle les individus peuvent être séparés en deux groupes à l'aide d'une ou plusieurs variable (ex. test t, ANOVA).\n",
    "  - La conclusion de l'analyse sera appliquée au niveau des **groupes** d'inidividus.\n",
    "  - La généralisation des résultats dépendra du respect des postulats et de la gestion des données manquantes/extrêmes/influentes.\n",
    "  \n",
    "  \n",
    "- En apprentissage machine, on tentera plutôt de prédire auquel des groupes appartiendra un individu futur en fonction de mesures sur une ou plusieurs variables.\n",
    "  - La conclusion de l'analyse est applicable au niveau des **individus**.\n",
    "  - La généralisation des résultats sera évaluée à l'aide d'un ensemble \"test\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Régression logistique\n",
    "\n",
    "\n",
    "- On peut réutiliser la régression linéaire présentée à la section 3 pour solutionner un problème de classification.\n",
    "\n",
    "\n",
    "- Cependant, la valeur prédite n'est pas la somme des valeurs pondérées des prédicteurs.\n",
    "  - Plutôt, on applique une fonction en sortie qui estime si la valeur prédite est positive ou négative.\n",
    "  - Si la valeur est positive, alors on classe l'observation dans la classe A.\n",
    "  - Si la valeur est négative, alors on classe l'observation dans la classe B.\n",
    "  \n",
    "$$\\hat{Y} = \\hat{\\beta_0} + \\hat{\\beta_1}X_1 + \\hat{\\beta_2}X_2 + ... + \\hat{\\beta_p}X_p > 0$$\n",
    "\n",
    "\n",
    "- Ainsi, la régression correspond ici à la **frontière** entre les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 1: importer les librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 2: importer les fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Régression linéaire multiple (Lasso)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 2 (modifications pour Lasso avec validation croisée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ================================================== Modification ============================================\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "# from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso  # On change \"Ridge\" pour \"Lasso\" \n",
    "# ============================================================================================================\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 4 (modifications pour Lasso avec validation croisée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# ================================================== Modification ============================================\n",
    "\n",
    "# On change l'utilisation de la fonction \"Ridge\" pour \"Lasso\"\n",
    "\n",
    "# Entraînons notre modèle\n",
    "lasso_001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "lasso_01 = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "lasso_1 = Lasso(alpha=1).fit(X_train, y_train)\n",
    "lasso_10 = Lasso(alpha=10).fit(X_train, y_train)\n",
    "lasso_100 = Lasso(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "# Faisons trois itérations d'une validation croisée à 5 \"folds\"\n",
    "scores_001 = cross_val_score(lasso_001, X_train, y_train, cv=5)  # alpha=0.01\n",
    "scores_01 = cross_val_score(lasso_01, X_train, y_train, cv=5)  # alpha=0.1\n",
    "scores_1 = cross_val_score(lasso_1, X_train, y_train, cv=5)  # alpha=1\n",
    "scores_10 = cross_val_score(lasso_10, X_train, y_train, cv=5)  # alpha=10\n",
    "scores_100 = cross_val_score(lasso_100, X_train, y_train, cv=5)  # alpha=100\n",
    "# ============================================================================================================\n",
    "\n",
    "# Affichons les performances pour chaque alpha\n",
    "print(\"scores_001: Accuracy: %0.2f (+/- %0.2f)\" % (scores_001.mean(), scores_001.std() * 2))\n",
    "print(\"scores_01:  Accuracy: %0.2f (+/- %0.2f)\" % (scores_01.mean(), scores_01.std() * 2))\n",
    "print(\"scores_1:   Accuracy: %0.2f (+/- %0.2f)\" % (scores_1.mean(), scores_1.std() * 2))\n",
    "print(\"scores_10:  Accuracy: %0.2f (+/- %0.2f)\" % (scores_10.mean(), scores_10.std() * 2))\n",
    "print(\"scores_100: Accuracy: %0.2f (+/- %0.2f)\" % (scores_100.mean(), scores_10.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons l'échantillon de données \"Boston Housing dataset\"\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "\n",
    "# Séparons aléatoirement nos données en deux sous-ensembles \"Entraînement\" et \"Test\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Entraînons notre modèle\n",
    "lasso_001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "lasso_01 = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "lasso_1 = Lasso(alpha=1).fit(X_train, y_train)\n",
    "lasso_10 = Lasso(alpha=10).fit(X_train, y_train)\n",
    "lasso_100 = Lasso(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Faisons trois itérations d'une validation croisée à 5 \"folds\"\n",
    "scores_001 = cross_val_score(lasso_001, X_train, y_train, cv=5)  # alpha=0.01\n",
    "scores_01 = cross_val_score(lasso_01, X_train, y_train, cv=5)  # alpha=0.1\n",
    "scores_1 = cross_val_score(lasso_1, X_train, y_train, cv=5)  # alpha=1\n",
    "scores_10 = cross_val_score(lasso_10, X_train, y_train, cv=5)  # alpha=10\n",
    "scores_100 = cross_val_score(lasso_100, X_train, y_train, cv=5)  # alpha=100\n",
    "\n",
    "# Affichons les performances pour chaque alpha\n",
    "print(\"scores_001: Accuracy: %0.2f (+/- %0.2f)\" % (scores_001.mean(), scores_001.std() * 2))\n",
    "print(\"scores_01:  Accuracy: %0.2f (+/- %0.2f)\" % (scores_01.mean(), scores_01.std() * 2))\n",
    "print(\"scores_1:   Accuracy: %0.2f (+/- %0.2f)\" % (scores_1.mean(), scores_1.std() * 2))\n",
    "print(\"scores_10:  Accuracy: %0.2f (+/- %0.2f)\" % (scores_10.mean(), scores_10.std() * 2))\n",
    "print(\"scores_100: Accuracy: %0.2f (+/- %0.2f)\" % (scores_100.mean(), scores_10.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Sélectionner le modèle ayant l'alpha le plus performant sur l'ensemble de validation \n",
    "lasso = lasso_001\n",
    "\n",
    "# Affichons les tailles d'effet R-deux\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"ridge.coef_: {}\".format(lasso.coef_))\n",
    "print(\"ridge.intercept_: {}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction permettant d'importer un jeu de données sur le cancer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lasso_001.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(ridge_01.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 3:  importer et préparer le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer le jeux de données d'entraînement et de test.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Séparons aléatoirement nos données en deus sous-ensembles \"Entraînement\" et \"Test\".\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 4: définir et entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "logreg=LogisticRegression(solver='lbfgs', max_iter=100000)\n",
    "\n",
    "# Entraîner le modèle\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 5: vérifier la généralisabilité des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "print('Classification report: \\n\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limites de la régression logistique\n",
    "\n",
    "- Les paramètres du modèle sont instables si:\n",
    "  - Si les classes sont relativement bien séparées;\n",
    "  - Si N est petit.\n",
    "  \n",
    "  \n",
    "- Si on a plus de deux classes, on doit faire une série de régression logistiques, car autant de frontières que de classes.\n",
    "  - Chaque chaque frontière sépare une classe du reste des classes.\n",
    "  \n",
    "- Néanmoins, quand on a suffisamment de données, la régression logistique est une méthode efficace et rapide pour les cas où on a seulement une décision binaire à faire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Analyse discriminante linéaire\n",
    "\n",
    "- L'analyse discriminante linéaire permet de pallier les limites de la régression logistique.\n",
    "\n",
    "- Elle a pour objectif de:\n",
    "  - Maximiser la différence entre les centroïdes des classes.\n",
    "  - Minimiser la variabilité à l'intérieur des classes.\n",
    "\n",
    "\n",
    "- Critère à minimiser:\n",
    "$$\\frac{\\mu_1 -\\mu_2}{s_1^2 + s_2^2}$$\n",
    "\n",
    "\n",
    "- L'analyse trouve d'abord un premier axe sur lequel projeter les observations.\n",
    "  - L'axe qui minimise le critère précédant.\n",
    "  \n",
    "\n",
    "- L'analyse trouve ensuite le deuxième axe minimisant le même critère... etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 1: importer les librairies utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 2: importer les fonctions utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction permettant d'importer un jeu de données sur le cancer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 3: importer et préparer le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer le jeux de données d'entraînement et de test.\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Séparons aléatoirement nos données en deus sous-ensembles \"Entraînement\" et \"Test\".\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 4: définir et entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "lda= LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Entraîner le modèle\n",
    "lda_model = lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÉTAPE 5: vérifier la généralisabilité des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Test set score: {:.3f}\".format(lda.score(X_test, y_test)))\n",
    "\n",
    "y_pred = lda_model.predict(X_test)\n",
    "\n",
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "print('Classification report: \\n\\n', classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
