{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_vs_ANS_txt_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_1_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_2_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_3_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4_txt_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/AS_4_txt_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/cours_2_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/R_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/R_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_11.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_12.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_13.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_14.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_15.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_16.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_17.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_18.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_19.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_20.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_21.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_22.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_23.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_24.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_25.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_26.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_27.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_28.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_29.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_30.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_31.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# instantiate model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Affichons les tailles d'effet R-deux\n",
    "print(\"\\nTest mse: \", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire de sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# instantiate model\n",
    "#model = LinearRegression()\n",
    "#model = Ridge(alpha = 10)\n",
    "model = Lasso(alpha = .1)\n",
    "#model = ElasticNet(alpha=.01, l1_ratio = .05)\n",
    "\n",
    "# fit \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"lr.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nlr.intercept_: {}\".format(model.intercept_))\n",
    "\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Affichons les tailles d'effet R-deux\n",
    "print(\"\\nTest mse: \", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "mse_test_min = mse_test\n",
    "\n",
    "for i in range(7):\n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    \n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "for i in range(7):\n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    if mse_test < mse_test_min:\n",
    "        mse_test_min = mse_test\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        by_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "        \n",
    "        if mse_test < mse_test_min:\n",
    "            mse_test_min = mse_test\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nTest mse: \", mse_test)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_32.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_33.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        \n",
    "        mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "        mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "        \n",
    "        if mse_valid < mse_valid_min:\n",
    "            mse_valid_min = mse_valid\n",
    "            print(\"\\n\\nalgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nTraining mse: \", mse_train)\n",
    "            print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model_best = 'Lasso'\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final, max_iter=100000)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train_full = mean_squared_error(y_train_full, y_train_full_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nAlgorithm: \", model_best)\n",
    "print(\"\\nAlpha: \", alpha_final)\n",
    "print(\"\\nTraining mse: \", mse_train_full)\n",
    "print(\"\\nTest mse: \", mse_test)\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full = scaler.fit_transform(X_train_full)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "\n",
    "\n",
    "mse_valid_min = mse_valid\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nTraining mse: \", mse_train)\n",
    "print(\"\\nValidation mse: \", mse_valid)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = SGDRegressor(alpha = 0.0001*(10**i), max_iter=100000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    mse_valid = mean_squared_error(y_valid, y_valid_pred)\n",
    "    \n",
    "    if mse_valid < mse_valid_min:\n",
    "        mse_valid_min = mse_valid\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nTraining mse: \", mse_train)\n",
    "        print(\"\\nValidation mse: \", mse_valid)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_34.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_35.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_36.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_37.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_38.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_39.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print(np.mean(X_train[:,0]))\n",
    "print(np.mean(X_train[:,0]))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "r2_max = np.mean(r2_scores)\n",
    "\n",
    "print(\"\\n\\nalgorithm: vanilla\")\n",
    "print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Ridge\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Ridge(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    if np.mean(r2_scores) > r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nalgorithm: Ridge\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : Lasso\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    model = Lasso(alpha = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "    r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "    if np.mean(r2_scores) > r2_max:\n",
    "        r2_max = np.mean(r2_scores)\n",
    "        print(\"\\n\\nAlgorithme: Lasso\")\n",
    "        print(\"\\nalpha: \", 0.001*(10**i))\n",
    "        print(\"\\nMoyenne r2: \", r2_max)\n",
    "\n",
    "# Linear regression : ElasticNet\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        \n",
    "        model = ElasticNet(alpha=0.001*(10**i), l1_ratio = 0.001*(10**i), max_iter=100000)\n",
    "    \n",
    "        r2_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "        if np.mean(r2_scores) > r2_max:\n",
    "            r2_max = np.mean(r2_scores)\n",
    "            print(\"\\n\\nAlgorithm: ElasticNet\")\n",
    "            print(\"\\nalpha: \", 0.001*(10**i))\n",
    "            print(\"\\nl1_ratio: \", 0.001*(10**j))\n",
    "            print(\"\\nMoyenne r2: \", r2_max)\n",
    "            \n",
    "print(\"\\n\\n Algorithm finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model_best = 'Lasso'\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train_full = r2_score(y_train_full, y_train_full_pred)\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nAlgorithm: \", model_best)\n",
    "print(\"\\nAlpha: \", alpha_final)\n",
    "print(\"\\nTraining r2: \", r2_train_full)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "k_folds = 10\n",
    "\n",
    "# vanilla\n",
    "\n",
    "lr = Pipeline(steps = [('scaler', StandardScaler()), ('model', LinearRegression())])\n",
    "lr_score = cross_val_score(lr, X_train, y_train, cv=k_folds)\n",
    "print('\\n\\nVanilla')\n",
    "print('\\nScore r2 = ', np.mean(lr_score))\n",
    "\n",
    "# Ridge\n",
    "\n",
    "model = Ridge(max_iter = 100000)\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nRidge')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "print(outer_cv)\n",
    "\n",
    "\n",
    "# Lasso\n",
    "\n",
    "model = Lasso()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nLasso')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "# ElasticNet\n",
    "\n",
    "model = ElasticNet()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\\\n",
    "         'model__l1_ratio':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nElasticNet')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "#print('Moyenne des scores r2: ', np.mean(gscv))\n",
    "#print('Écart type des scores r2: ', np.mean(r2_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model_best = 'Lasso'\n",
    "alpha_final = .1\n",
    "\n",
    "model = Lasso(alpha = alpha_final)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "\n",
    "y_train_full_pred = model.predict(X_train_full)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "r2_train_full = r2_score(y_train_full, y_train_full_pred)\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\\nAlgorithm: \", model_best)\n",
    "print(\"\\nAlpha: \", alpha_final)\n",
    "print(\"\\nTraining r2: \", r2_train_full)\n",
    "print(\"\\nTest r2: \", r2_test)\n",
    "\n",
    "# Affichons les valeurs des coefficients\n",
    "print(\"\\nmodel.coef_: {}\".format(model.coef_))\n",
    "print(\"\\nmodel.intercept_: {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/R_40.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Importer le modèle de régression linéaire\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTT']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : entraîner le modèle (ensemble \"Entraînement\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Linear regression : vanilla\n",
    "\n",
    "k_folds = 10\n",
    "\n",
    "# vanilla\n",
    "\n",
    "lr = Pipeline(steps = [('scaler', StandardScaler()), ('model', LinearRegression())])\n",
    "lr_score = cross_val_score(lr, X_train, y_train, cv=k_folds)\n",
    "print('\\n\\nVanilla')\n",
    "print('\\nScore r2 = ', np.mean(lr_score))\n",
    "\n",
    "# Ridge\n",
    "\n",
    "model = Ridge(max_iter = 100000)\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X, y)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\n\\nRidge')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n",
    "# Lasso\n",
    "\n",
    "model = Lasso()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nLasso')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n",
    "# ElasticNet\n",
    "\n",
    "model = ElasticNet()\n",
    "pipe = Pipeline(steps = [('scaler', StandardScaler()), ('model', model)])\n",
    "params = {'model__alpha':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000],\\\n",
    "         'model__l1_ratio':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=params, cv=k_folds)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "best_score = grid_result.best_score_\n",
    "print('\\nElasticNet')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore r2 = ', best_score)\n",
    "\n",
    "outer_cv = cross_val_score(grid, X, y, cv = 5)\n",
    "\n",
    "print('\\nTest r2 = ', np.mean(outer_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./img/C_titre.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_11.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_12.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_13.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_14.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_15.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_16.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"./img/C_17.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importer les librairies utiles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=100000)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('\\n\\n\\n\\nPHASE ENTRAÏNEMENT\\n\\n')\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "cfm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "accuracy  = accuracy_score(y_train, y_train_pred)\n",
    "precision = precision_score(y_train, y_train_pred)\n",
    "recall    = recall_score(y_train, y_train_pred)\n",
    "f1        = f1_score(y_train, y_train_pred)\n",
    "\n",
    "print('Justesse: \\n\\n', accuracy, '\\n\\n')\n",
    "print('Précision: \\n\\n', precision, '\\n\\n')\n",
    "print('Rappel: \\n\\n', recall, '\\n\\n')\n",
    "print('Score F1: \\n\\n', f1, '\\n\\n')\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 5 : vérifier la généralisabilité des résultats (ensemble \"Test\")\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print('\\n\\n\\n\\nPHASE TEST\\n\\n')\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "cfm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "accuracy  = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall    = recall_score(y_test, y_test_pred)\n",
    "f1        = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print('Justesse: \\n\\n', accuracy, '\\n\\n')\n",
    "print('Précision: \\n\\n', precision, '\\n\\n')\n",
    "print('Rappel: \\n\\n', recall, '\\n\\n')\n",
    "print('Score F1: \\n\\n', f1, '\\n\\n')\n",
    "\n",
    "print('Confusion matrix: \\n\\n', cfm, '\\n\\n')\n",
    "\n",
    "#print('Classification report: \\n\\n', classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
