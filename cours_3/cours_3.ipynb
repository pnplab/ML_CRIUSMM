{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/cours_3_0.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/SV_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <img src=\"./img/SV_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importer les librairies utiles pour l'analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importer les librairies utiles pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(font_scale=1.2)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "#features_cols = ['AUDITTT', 'STAIYTT']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print('Data ready')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model_logistic = LogisticRegression(solver='lbfgs')\n",
    "model_linear = svm.SVC(kernel='linear')\n",
    "model_rbf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "hyperparams_logistic = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "hyperparams_linear = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_logistic, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_logistic')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_linear, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_linear')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie l'algorithme final.\n",
    "#model_final = svm.SVC(kernel='linear', C=0.1)\n",
    "model_final = LogisticRegression(solver='lbfgs', C=.001)\n",
    "\n",
    "# On entrapine l'algorithme final.\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "# On teste l'algorithme final en prédisant de nouvelles données.\n",
    "y_pred = model_final.predict(X_test)\n",
    "\n",
    "# On évalue les prédictions de l'algorithme final.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# On affiche le résultat\n",
    "print('\\nTest f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <img src=\"./img/SV_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importer les librairies utiles pour l'analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "#features_cols = ['AUDITTT', 'STAIYTT']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print('Data ready')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model_logistic = LogisticRegression(solver='lbfgs')\n",
    "model_linear = svm.SVC(kernel='linear')\n",
    "model_rbf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "hyperparams_logistic = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "hyperparams_linear = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "hyperparams_rbf = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000], 'gamma':[.0001, .001, .01, .1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_logistic, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_logistic')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_linear, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_linear')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_rbf, param_grid=hyperparams_rbf, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_rbf')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie l'algorithme final.\n",
    "model_final = svm.SVC(kernel='rbf', C=0.1, gamma=0.1)\n",
    "#model_final = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "# On entrapine l'algorithme final.\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "# On teste l'algorithme final en prédisant de nouvelles données.\n",
    "y_pred = model_final.predict(X_test)\n",
    "\n",
    "# On évalue les prédictions de l'algorithme final.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# On affiche le résultat\n",
    "print('\\nTest f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/AD_0.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/AD_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/AD_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./img/AD_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importer les librairies utiles pour l'analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "#features_cols = ['AUDITTT', 'STAIYTT']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print('Data ready')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model_logistic = LogisticRegression(solver='lbfgs')\n",
    "model_linear = svm.SVC(kernel='linear')\n",
    "model_rbf = svm.SVC(kernel='rbf')\n",
    "model_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "hyperparams_logistic = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_linear = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_rbf = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000], 'gamma':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_tree = {'max_depth':[1, 2, 4, 8, 12, 16], 'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16]}\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_logistic, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_logistic')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_linear, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_linear')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_rbf, param_grid=hyperparams_rbf, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_rbf')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_tree, param_grid=hyperparams_tree, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\ntree')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie l'algorithme final.\n",
    "#model_final = LogisticRegression(solver='lbfgs')\n",
    "#model_final = svm.SVC(kernel='linear', C=0.0001) \n",
    "#model_final = svm.SVC(kernel='rbf', C=0.1, gamma=0.1) \n",
    "model_final = DecisionTreeClassifier(max_depth=4, min_samples_split=2)\n",
    "\n",
    "# On entrapine l'algorithme final.\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "# On teste l'algorithme final en prédisant de nouvelles données.\n",
    "y_pred = model_final.predict(X_test)\n",
    "\n",
    "# On évalue les prédictions de l'algorithme final.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# On affiche le résultat\n",
    "print('\\nTest f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/AD_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_0.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/FA_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importer les librairies utiles pour l'analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "#features_cols = ['AUDITTT', 'STAIYTT']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print('Data ready')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model_logistic = LogisticRegression(solver='lbfgs')\n",
    "model_linear = svm.SVC(kernel='linear')\n",
    "model_rbf = svm.SVC(kernel='rbf')\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "hyperparams_logistic = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_linear = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_rbf = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000], 'gamma':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_tree = {'max_depth':[1, 2, 4, 8, 12, 16], 'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16]}\n",
    "hyperparams_forest = {'n_estimators':[5, 10, 20, 50], \\\n",
    "                      'max_depth':[1, 2, 4, 8, 12, 16], \\\n",
    "                      'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16], \\\n",
    "                      'max_features': [1, 3, 5, 7, 9]}\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_logistic, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_logistic')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_linear, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_linear')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_rbf, param_grid=hyperparams_rbf, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_rbf')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_tree, param_grid=hyperparams_tree, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\ntree')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_forest, param_grid=hyperparams_forest, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nforest')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On spécifie l'algorithme final.\n",
    "#model_final = LogisticRegression(solver='lbfgs')\n",
    "#model_final = svm.SVC(kernel='linear', C=0.0001) \n",
    "#model_final = svm.SVC(kernel='rbf', C=0.1, gamma=0.1) \n",
    "#model_final = DecisionTreeClassifier(max_depth=4, min_samples_split=2)\n",
    "model_final = RandomForestClassifier(n_estimators=10, max_depth=4, min_samples_split=2, max_features=3)\n",
    "\n",
    "\n",
    "# On entrapine l'algorithme final.\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "# On teste l'algorithme final en prédisant de nouvelles données.\n",
    "y_pred = model_final.predict(X_test)\n",
    "\n",
    "# On évalue les prédictions de l'algorithme final.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# On affiche le résultat\n",
    "print('\\nTest f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_0.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_1.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_2.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_3.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_4.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_5.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_6.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_7.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_8.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_9.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_10.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/BG_11.svg\" alt=\"Drawing\" style=\"width: 2000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready\n",
      "\n",
      "forest\n",
      "\n",
      "Meilleur paramètre:  {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 7, 'min_samples_split': 12, 'n_estimators': 10}\n",
      "\n",
      "Score f1 =  0.7447444450275084\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore',category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 1 : importer les librairies utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Importer les librairies utiles pour l'analyse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 2 : importer les fonctions utiles\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer une fonction qui nous permette de construire aléatoirement les ensembles \"Entraînement\" et \"Test\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importer le modèle de régression logistique de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Importer la fonction de validation croisée\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Importer la fonction permettant d'afficher le rapport de classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 3 : importer et préparer le jeu de données \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Importons un ensemble de données\n",
    "data = pd.read_csv('../data/sim_data_signature_small.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "features_cols = ['PSQ_SS', 'PHQ9TT', 'CEVQOTT', 'DAST10TT', 'AUDITTT', 'STAIYTT', 'AGE', 'SEXE', 'SES']\n",
    "#features_cols = ['AUDITTT', 'STAIYTT']\n",
    "\n",
    "X = data.loc[:, features_cols]\n",
    "y = data['WHODASTTB']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "print('Data ready')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ÉTAPE 4 : définir et entraîner le modèle\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Définir le modèle\n",
    "model_logistic = LogisticRegression(solver='lbfgs')\n",
    "model_linear = svm.SVC(kernel='linear')\n",
    "model_rbf = svm.SVC(kernel='rbf')\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_forest = RandomForestClassifier()\n",
    "model_boosting = GradientBoostingClassifier()\n",
    "\n",
    "# Définir les hyperparamètres\n",
    "hyperparams_logistic = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_linear = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_rbf = {'C':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000], 'gamma':[.0001, .001, .01, .1, 1, 10, 100, 1000, 1000]}\n",
    "hyperparams_tree = {'max_depth':[1, 2, 4, 8, 12, 16], 'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16]}\n",
    "hyperparams_forest = {'n_estimators':[5, 10, 20, 50], \\\n",
    "                      'max_depth':[1, 2, 4, 8, 12, 16], \\\n",
    "                      'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16], \\\n",
    "                      'max_features': [1, 3, 5, 7, 9]}\n",
    "hyperparams_boosting = {'learning_rate':[0.1, 0.2, 0.4, 0.8], \\\n",
    "                      'n_estimators':[10, 50], \\\n",
    "                      'max_depth':[1, 2, 4, 8, 12, 16], \\\n",
    "                      'min_samples_split':[2, 4, 6, 8, 10, 12, 14, 16], \\\n",
    "                      'max_features': [1, 3, 5, 7, 9]}\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_logistic, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_logistic')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_linear, param_grid=hyperparams_linear, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_linear')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_rbf, param_grid=hyperparams_rbf, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nSVC_rbf')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_tree, param_grid=hyperparams_tree, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\ntree')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_forest, param_grid=hyperparams_forest, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nforest')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)\n",
    "\n",
    "cv_valid = GridSearchCV(estimator=model_boosting, param_grid=hyperparams_boosting, cv=cv_folds, scoring='f1', iid=False)\n",
    "cv_valid.fit(X_train, y_train)\n",
    "best_params = cv_valid.best_params_\n",
    "best_score = cv_valid.best_score_\n",
    "print('\\nforest')\n",
    "print('\\nMeilleur paramètre: ', best_params)\n",
    "print('\\nScore f1 = ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test f1 =  0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "# On spécifie l'algorithme final.\n",
    "#model_final = LogisticRegression(solver='lbfgs')\n",
    "#model_final = svm.SVC(kernel='linear', C=0.0001) \n",
    "#model_final = svm.SVC(kernel='rbf', C=0.1, gamma=0.1) \n",
    "#model_final = DecisionTreeClassifier(max_depth=4, min_samples_split=2)\n",
    "#model_final = RandomForestClassifier(n_estimators=10, max_depth=4, min_samples_split=2, max_features=3)\n",
    "model_final = GradientBoostingClassifier(learning_rate=0.1, n_estimators=10, max_depth=4, min_samples_split=12, max_features=7)\n",
    "\n",
    "\n",
    "# On entrapine l'algorithme final.\n",
    "model_final.fit(X_train, y_train)\n",
    "\n",
    "# On teste l'algorithme final en prédisant de nouvelles données.\n",
    "y_pred = model_final.predict(X_test)\n",
    "\n",
    "# On évalue les prédictions de l'algorithme final.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# On affiche le résultat\n",
    "print('\\nTest f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Il manque seulement :\n",
    "- Tableau des avantages/inconvénients de chacune des méthodes.\n",
    "- Présentation de la ROC\n",
    "\n",
    "- Je ne crois pas qu'on ait le temps pour knn. Or, on pourrait l'introduire rapidement après k-means dans le cours sur le non-supervisé (montrer une méthode similaire utilisable en supervisé)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
